{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bR4O8vRDKy1C"
   },
   "source": [
    "# Natural Language Processing \n",
    "### CS-UH 2216 - Spring 2019\n",
    "## Sentiment Analysis of 100,000 IMDB movie reviews\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Imdb movie review data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb/imdbEr.txt  aclImdb/imdb.vocab\taclImdb/README\r\n",
      "\r\n",
      "aclImdb/test:\r\n",
      "labeledBow.feat  neg  pos  urls_neg.txt  urls_pos.txt\r\n",
      "\r\n",
      "aclImdb/train:\r\n",
      "labeledBow.feat  pos\tunsupBow.feat  urls_pos.txt\r\n",
      "neg\t\t unsup\turls_neg.txt   urls_unsup.txt\r\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "import os\n",
    "\n",
    "# The code below will check to see if the data directory exists; if not, it will download the data.\n",
    "if os.path.exists(\"./aclImdb\") == False:\n",
    "    print(\"Downloading the Imdb movie review data set\")\n",
    "    !wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "    !tar xf aclImdb_v1.tar.gz\n",
    "#Shell command to show the files and directories we have under aclImdb\n",
    "!ls aclImdb/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positive training examples:\n",
      "12500\n",
      "number of negative training examples:\n",
      "12500\n",
      "number of unlabelled training examples:\n",
      "50000\n",
      "number of positive testing examples:\n",
      "12500\n",
      "number of negative testing examples:\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "#Run this cell first\n",
    "print(\"number of positive training examples:\")\n",
    "pos_train = !ls aclImdb/train/pos/ | wc -l\n",
    "pos_train = int(pos_train[0])\n",
    "print(pos_train)\n",
    "print(\"number of negative training examples:\")\n",
    "neg_train = !ls aclImdb/train/neg/ | wc -l\n",
    "neg_train = int(neg_train[0])\n",
    "print(neg_train)\n",
    "print(\"number of unlabelled training examples:\")\n",
    "unl_train = !ls aclImdb/train/unsup/ | wc -l\n",
    "unl_train = int(unl_train[0])\n",
    "print(unl_train)\n",
    "print(\"number of positive testing examples:\")\n",
    "pos_test = !ls aclImdb/test/pos/ | wc -l\n",
    "pos_test = int(pos_test[0])\n",
    "print(pos_test)\n",
    "print(\"number of negative testing examples:\")\n",
    "neg_test = !ls aclImdb/test/pos/ | wc -l\n",
    "neg_test = int(neg_test[0])\n",
    "print(neg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 How many reviews are for training? 75000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of training reviews:\n",
      "75000\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of training reviews:\" )\n",
    "print(pos_train + neg_train + unl_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 How many reviews are for testing? 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of training reviews:\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of training reviews:\" )\n",
    "print(pos_test + neg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 How many reviews are positive (in total in training and testing)? 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total positive instances in training and testing\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(\"total positive instances in training and testing\" )\n",
    "print(pos_train + pos_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 How many reviews are negative (in total in training and testing)? 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total negative instances in training and testing\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(\"total negative instances in training and testing\" )\n",
    "print(neg_train + neg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 How many reviews are unlabelled (in total in training and testing)? 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total negative instances in training and testing\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(\"total negative instances in training and testing\" )\n",
    "print(unl_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 What can we use unlabeled reviews for? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the unlabeled reviews for building unsupervised learning classification algorithms that can cluster and learn labels of reviews without being given the rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 How was the positive/negative labeling done?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive and negative labels are classified based on the rating of the user reviews. A negative class is given to ratings <= 4 and a positive class is given to ratings >= 7 out of 10. Hence, reviews with more neural ratings are not included in the positive/negative sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 Simply based on the labeling approach, do we expect some reviews to be harder than others for sentiment analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. This is because some reviews with the same label(pos/neg class) are closer to the extreme ends of the scale (1 ratings) while other reviews are closer to the neural end (4 rating). We would expect reviews with the same label but closer to the extreme end of the scale, to be easier to analyze because they likely have more obvious features which we can use for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9 How many are the most negative review [1] (train and test)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of most negative reviews\n",
      "10122\n"
     ]
    }
   ],
   "source": [
    "max_neg_test = !ls aclImdb/test/neg/ | grep \"\\w*1.txt\" | wc -l\n",
    "max_neg_test = int(max_neg_test[0])\n",
    "max_neg_train = !ls aclImdb/train/neg/ | grep \"\\w*1.txt\" | wc -l\n",
    "max_neg_train = int(max_neg_train[0])\n",
    "print(\"Total number of most negative reviews\")\n",
    "print(max_neg_test + max_neg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.10 How many are the most positive reviews [10] (train and test)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of most positive reviews\n",
      "9731\n"
     ]
    }
   ],
   "source": [
    "max_pos_test = !ls aclImdb/test/pos/ | grep \"\\w*10.txt\" | wc -l\n",
    "max_pos_test = int(max_pos_test[0])\n",
    "max_pos_train = !ls aclImdb/train/pos/ | grep \"\\w*10.txt\" | wc -l\n",
    "max_pos_train = int(max_pos_train[0])\n",
    "print(\"Total number of most positive reviews\")\n",
    "print(max_pos_test + max_pos_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_files #load_files load text files with categories as subfolder names; \n",
    "\n",
    "# Directory of our data\n",
    "traindir = r'./aclImdb/train'\n",
    "testdir = r'./aclImdb/test'\n",
    "\n",
    "# load pos/neg train and test data\n",
    "train=load_files(traindir,categories=['pos','neg']) #load_files shuffles the text and categories by default.\n",
    "test=load_files(testdir,categories=['pos','neg'])\n",
    "\n",
    "# load an object with all the training data (positive, negative and unlabeled)\n",
    "alltrain = load_files(traindir,categories=['pos','neg','unsup'])\n",
    "#load_files return a dictionary-like object:\n",
    "#1. 'data': the raw text data to learn\n",
    "#2. 'target': the classification labels (integer index)\n",
    "#3. 'target_names': the meaning of the labels\n",
    "#4. 'filenames': the name of the file holding the data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index  = 13374\n",
      "\n",
      "Text = b'Since this movie was based on a true story of a woman who had two children and was not very well-off, it was just scary as to how real it really was! The acting is what gave the movie that push to greatness.<br /><br />Diane Keaton portrayed the main character, Patsy McCartle who had two sons whom she adored. Her performance is what made the real life story come to life on a television screen. It was very hard to watch some of the scenes since they were so real as to what happens when one becomes addicted to drugs.<br /><br />Just watching this very loving mother go from sweet to not caring at all was hard, but so true. I have known people who have gone through withdrawl and it was very much like what happened in this movie, from what I remember.<br /><br />I also thought that it was very risky for the director to want to make a movie out of what happened to this woman. Yet it was done so well. I applaud the director for making this movie.<br /><br />I highly recommend this to anyone who has known someone who has ever been addicted to drugs or to just learn what can happen to you if you do become addicted to them.'\n",
      "\n",
      "Label = pos\n",
      "\n",
      "Filename = ./aclImdb/train/pos/1953_10.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Browse an example\n",
    "#For example, if we want to see data point with index i \n",
    "i = 13374\n",
    "print(\"Index  = %3d\\n\" % (i))\n",
    "print(\"Text = %s\\n\" % (train.data[i]))\n",
    "print(\"Label = %s\\n\" %(train.target_names[train.target[i]]))\n",
    "print(\"Filename = %s\\n\" % (train.filenames[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Investigating the quality of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to determine rating given the review filename\n",
    "import re\n",
    "def getRating(filename):\n",
    "    match = re.search(\"_(.+).txt\",filename)\n",
    "    if match: #If we have found something\n",
    "        return(int(match.group(1))) #Return the first capture group ()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_print_rating(rating):\n",
    "    #listing filename, label, and at least the first 10 words of text\n",
    "    for i in range(len(train.filenames)):\n",
    "        if(getRating(train.filenames[i]) == rating):\n",
    "            print(\"Label = %s\" %(train.target_names[train.target[i]]))\n",
    "            print(\"Filename: \", train.filenames[i])\n",
    "            print(\"Rating: \", getRating(train.filenames[i]))\n",
    "            print(\"Text: \", train.data[i][0:200])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Identify an example of a strong negative sentiment based on human ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = neg\n",
      "Filename:  ./aclImdb/train/neg/6802_1.txt\n",
      "Rating:  1\n",
      "Text:  b\"Words can't describe how bad this movie is. I can't explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do th\"\n"
     ]
    }
   ],
   "source": [
    "find_and_print_rating(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Identify an example of a weak negative sentiment based on human ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = neg\n",
      "Filename:  ./aclImdb/train/neg/9503_4.txt\n",
      "Rating:  4\n",
      "Text:  b'Also known in a different form as \"House of Exorcism,\" this messy<br /><br />little film takes itself so seriously as to kill any entertainment value<br /><br />whatsoever.<br /><br />The spare plot i'\n"
     ]
    }
   ],
   "source": [
    "find_and_print_rating(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Identify an example of a strong positive sentiment based on human ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = pos\n",
      "Filename:  ./aclImdb/train/pos/11485_10.txt\n",
      "Rating:  10\n",
      "Text:  b'Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of be'\n"
     ]
    }
   ],
   "source": [
    "find_and_print_rating(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Identify an example of a weak positive sentiment based on human ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = pos\n",
      "Filename:  ./aclImdb/train/pos/9846_7.txt\n",
      "Rating:  7\n",
      "Text:  b'Ok, at the beginning it looked like \"Shrek\" - the loner that is persistently followed by the comic relief. Then it evolves into something really compelling, as the gauntlet is set. And the result is a'\n"
     ]
    }
   ],
   "source": [
    "find_and_print_rating(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 List one observation of a feature of the text that you think will be helpful to predict sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the choice of vocabulary seems to be correlated with the rating of the review. Certain vocabulary such as \"Horrible\" are seen significantly more frequently in negative instances than in positive instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times \"horrible\" appeared in negative reviews:  796\n",
      "Number of times \"horrible\" appeared in positive reviews:  150\n"
     ]
    }
   ],
   "source": [
    "#Number of reviews with \"Horrible\" in contents.\n",
    "negativeOccurances = 0\n",
    "positiveOccurances = 0\n",
    "for i in range(len(train.filenames)):\n",
    "    if(train.target_names[train.target[i]] == 'pos'):\n",
    "        if 'horrible' in str(train.data[i]):\n",
    "            positiveOccurances += 1\n",
    "    else:\n",
    "        if 'horrible' in str(train.data[i]):\n",
    "            negativeOccurances += 1\n",
    "print(\"Number of times \\\"horrible\\\" appeared in negative reviews: \", negativeOccurances)\n",
    "print(\"Number of times \\\"horrible\\\" appeared in positive reviews: \", positiveOccurances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building a basic sentiment analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize our text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #Vectorize our text with top 1000 frequent vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the vectorizer and transform our data\n",
    "vectorizer = CountVectorizer(max_features=1000,analyzer='word',lowercase=True) #Tokenize at word level\n",
    "vectorizer.fit(alltrain.data)\n",
    "train_data_vectorized = vectorizer.transform(train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a logistic linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(train_data_vectorized, train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  = 85.96%\n",
      "Average Precision = 85.97%\n",
      "Average Recall    = 85.96%\n",
      "Average F1-score  = 85.95%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "test_pred = model.predict(vectorizer.transform(test.data))\n",
    "#Preliminary evaluation with sklearn\n",
    "print (\"Accuracy  = %3.2f%%\" % (100*accuracy_score(test.target, test_pred)))\n",
    "print (\"Average Precision = %3.2f%%\" % (100*precision_score(test.target, test_pred, average='macro')))\n",
    "print (\"Average Recall    = %3.2f%%\" % (100*recall_score(test.target, test_pred, average='macro')))\n",
    "print (\"Average F1-score  = %3.2f%%\" % (100*f1_score(test.target, test_pred, average='macro')))\n",
    "# The scores for accuracy, and average precision, recall and F1-score are similar. \n",
    "# This is in part an effect of the balanced nature of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Evaluating Accuracy, Recall and F1 scores without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances 25000\n",
      "Total correct predictions 21489\n",
      "Correctly predicted negative 10617\n",
      "Incorrectly predicted negative 1883\n",
      "Correctly predicted positive 10872\n",
      "Incorrectly predicted positive 1628\n"
     ]
    }
   ],
   "source": [
    "#Record the instances of correct and incorrect predictions\n",
    "num_neg = 0\n",
    "num_pos = 0\n",
    "neg_correct = 0\n",
    "neg_incorrect = 0\n",
    "pos_correct = 0\n",
    "pos_incorrect = 0\n",
    "\n",
    "for i in range(len(test.target)):\n",
    "    if test.target[i] == 0:\n",
    "        num_neg +=1\n",
    "        if test_pred[i] == 0:\n",
    "            neg_correct += 1\n",
    "        elif test_pred[i] == 1:\n",
    "            neg_incorrect += 1\n",
    "    elif test.target[i] == 1:\n",
    "        num_pos += 1\n",
    "        if test_pred[i] == 0:\n",
    "            pos_incorrect += 1\n",
    "        elif test_pred[i] == 1:\n",
    "            pos_correct += 1\n",
    "\n",
    "print(\"Total instances %d\" % (num_neg + num_pos))\n",
    "print(\"Total correct predictions %d\" % (pos_correct + neg_correct) )\n",
    "print(\"Correctly predicted negative %d\" % (neg_correct))\n",
    "print(\"Incorrectly predicted negative %d\" % (neg_incorrect))\n",
    "print(\"Correctly predicted positive %d\" % (pos_correct))\n",
    "print(\"Incorrectly predicted positive %d\" % (pos_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.96%\n",
      "\n",
      "Neg label precision: 86.70%\n",
      "Neg label recall: 84.94%\n",
      "Neg F1 score: 85.81%\n",
      "\n",
      "Pos label precision: 85.24%\n",
      "Pos label recall: 86.98%\n",
      "Pos F1 score: 86.10%\n",
      "\n",
      "Average precision 85.97\n",
      "Average recall 85.96\n",
      "Average F1 score 85.95%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy = Correctly predicted / Total\n",
    "Accuracy = (pos_correct + neg_correct)/(num_neg + num_pos)\n",
    "print(\"Accuracy: %2.2f%%\" % (100*Accuracy))\n",
    "print()\n",
    "\n",
    "#Neg label precision = neg_correct / (neg_correct + pos_incorrect)\n",
    "neg_precision = neg_correct / (neg_correct + pos_incorrect)\n",
    "print(\"Neg label precision: %2.2f%%\" % (100*neg_precision))\n",
    "\n",
    "#Recall of Neg = neg_correct / num_neg\n",
    "neg_recall = neg_correct / num_neg\n",
    "print(\"Neg label recall: %2.2f%%\" % (100*neg_recall))\n",
    "\n",
    "#F1-score harmonic mean of precision and recall. = \n",
    "neg_f1 = 1/( ((1/neg_precision)+(1/neg_recall))/2 )\n",
    "print(\"Neg F1 score: %2.2f%%\" % (100*neg_f1))\n",
    "print()\n",
    "\n",
    "#Pos label precision = pos_correct / (pos_correct + neg_incorrect)\n",
    "pos_precision = pos_correct / (pos_correct + neg_incorrect)\n",
    "print(\"Pos label precision: %2.2f%%\" % (100*pos_precision))\n",
    "\n",
    "#Recall of Pos = pos_correct / num_pos\n",
    "pos_recall = pos_correct / num_pos\n",
    "print(\"Pos label recall: %2.2f%%\" % (100*pos_recall))\n",
    "\n",
    "#F1-score harmonic mean of precision and recall. = \n",
    "pos_f1 = 1/( ((1/pos_precision)+(1/pos_recall))/2 )\n",
    "print(\"Pos F1 score: %2.2f%%\" % (100*pos_f1))\n",
    "print()\n",
    "\n",
    "print(\"Average precision %2.2f\" % (100*(neg_precision + pos_precision)/2))\n",
    "print(\"Average recall %2.2f\" % (100*(neg_recall + pos_recall)/2))\n",
    "print(\"Average F1 score %2.2f%%\" % (100*(neg_f1 + pos_f1)/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Individual accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Accuracy for each rating (1-4, 7-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating 1 accuracy: 91.48\n",
      "Rating 2 accuracy: 87.62\n",
      "Rating 3 accuracy: 81.74\n",
      "Rating 4 accuracy: 73.21\n",
      "\n",
      "Rating 7 accuracy: 79.11\n",
      "Rating 8 accuracy: 85.40\n",
      "Rating 9 accuracy: 89.46\n",
      "Rating 10 accuracy: 90.34\n"
     ]
    }
   ],
   "source": [
    "ratingCorrect = dict()\n",
    "ratingIncorrect = dict()\n",
    "ratings = [1,2,3,4,7,8,9,10]\n",
    "#Initialize the ratings\n",
    "for rating in ratings:\n",
    "    ratingCorrect[rating] = 0\n",
    "    ratingIncorrect[rating] = 0\n",
    "    \n",
    "#Count correct and incorrect instances\n",
    "for i in range(len(test.target)):\n",
    "    rating = getRating(test.filenames[i])\n",
    "    if test.target[i] == test_pred[i]:\n",
    "        ratingCorrect[rating] += 1\n",
    "    else:\n",
    "        ratingIncorrect[rating] += 1\n",
    "\n",
    "# Print the accuracy.\n",
    "for rating in ratings:\n",
    "    print(\"Rating %d accuracy: %2.2f\" % (rating, 100*ratingCorrect[rating]/(ratingCorrect[rating]+ratingIncorrect[rating])))\n",
    "    if rating == 4:\n",
    "        print() #Print a space betwen \"positive\" and \"negative\" ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that our performance increases near the extreme for the negative class (1) and the extreme for the positive class (10). The performance decreases when the ratings are more neural and close to the center of the scale. This was predicted earlier in ยง 1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data samples for each instance in the cofusion matrix (TP FP FN TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze instances of TN(Neg Neg) FP (Neg Pos) FN(Pos Neg) and TP (Pos Pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInstance(gold, pred):\n",
    "    for i in range(len(test.target)):\n",
    "        if test.target[i] == gold and test_pred[i] == pred:\n",
    "            return(i)\n",
    "    return(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative\n",
      "Gold: Neg | Predicted: Neg | Match: Correct | Rating:  1\n",
      "Text:\n",
      "b'I don\\'t know how this movie has received so many positive comments. One can call it \"artistic\" and \"beautifully filmed\", but those things don\\'t make up for the empty plot that was filled with sexual innuendos. I wish I had not wasted my time to watch this movie. Rather than being biographical, it was a poor excuse for promoting strange and lewd behavior. It was just another Hollywood attempt to convince us that that kind of life is normal and OK. From the very beginning I asked my self what was the point of this movie,and I continued watching, hoping that it would change and was quite disappointed that it continued in the same vein. I am so glad I did not spend the money to see this in a theater!'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"True negative\")\n",
    "instance = getInstance(0,0)\n",
    "print(\"Gold: Neg | Predicted: Neg | Match: Correct | Rating: \", getRating(test.filenames[instance]))\n",
    "print(\"Text:\")\n",
    "print(test.data[instance])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This negative example was correctly predicted negatively. Since we are analyzing word frequency, this review has a lot of words such as \"dissapointed\" \"poor\" \"attempt\" and \"wasted\" which would have likely pushed the algorithm to predict a negative classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive\n",
      "Gold: Neg | Predicted: Pos | Match: Incorrect | Rating:  4\n",
      "Text:\n",
      "b\"Even Disney are guilty of the cash cow disease, after the roaring success of The Love Bug in 1968, the house of mouse cashed in with Herbie Rides Again, Herbie Goes To Monte Carlo, and Herbie Goes Bananas. Neither sequel capturing the charm and inoffensive appeal of The Love Bug back in 68, in this one we find race driver Jim Douglas and his sidekick Wheely Applegate, entering Herbie in the Monte Carlo Rally. Naturally things outside of the race start to take over priorities, they get mixed up in a diamond robbery and Herbie falls in love with another car!. The car stunts are of course pleasant and easy on the eye, and it would be churlish of me to really vent venom on such a friendly piece of fluff, it's just that the film goes nowhere fast and personally now i can see it for the coin motivated piece of work it is. Still you get to see Herbie take a bath, foil the baddies and of course dance for the lady in his life, so something there for everyone i think....................4/10.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"False positive\")\n",
    "instance = getInstance(0,1)\n",
    "print(\"Gold: Neg | Predicted: Pos | Match: Incorrect | Rating: \", getRating(test.filenames[instance]))\n",
    "print(\"Text:\")\n",
    "print(test.data[instance])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example was predicted to be positive when it was negative. First this example was a difficult review to classify as it's rating was quite near the center (4). Second, the review uses a lot of vocabulary such as \"love\" \"pleasant\" \"charm\" frequently which indicate that the reviewed liked the movie. The model doesn't know that the reviewer could be describing the contents of the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negative\n",
      "Gold: Pos | Predicted: Neg | Match: Incorrect | Rating:  7\n",
      "Text:\n",
      "b\"The casting of Robert Culp is probably the only decent move the production team made with this film. Falk and Culp were marvellous, but as culp was not Falks nemesis this time, chemistry was lacking. Columbo is only as strong as his opposite number, and this time he didn't have one.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"False negative\")\n",
    "instance = getInstance(1,0)\n",
    "print(\"Gold: Pos | Predicted: Neg | Match: Incorrect | Rating: \", getRating(test.filenames[instance]))\n",
    "print(\"Text:\")\n",
    "print(test.data[instance])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the above review, this review was also close to the center of the scale. In addition, even as a human reading the review, it would be difficult to predict the correct rating. The words used in this review doesn't indicate clearly that it is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive\n",
      "Gold: Pos | Predicted: Pos | Match: Correct | Rating:  9\n",
      "Text:\n",
      "b\"Don't hate Heather Graham because she's beautiful, hate her because she's fun to watch in this movie. Like the hip clothing and funky surroundings, the actors in this flick work well together. Casey Affleck is hysterical and Heather Graham literally lights up the screen. The minor characters - Goran Visnjic {sigh} and Patricia Velazquez are as TALENTED as they are gorgeous. Congratulations Miramax & Director Lisa Krueger!\"\n"
     ]
    }
   ],
   "source": [
    "print(\"True positive\")\n",
    "instance = getInstance(1,1)\n",
    "print(\"Gold: Pos | Predicted: Pos | Match: Correct | Rating: \", getRating(test.filenames[instance]))\n",
    "print(\"Text:\")\n",
    "print(test.data[instance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review was correctly predicted positive. It's likely because of the positive words used \"fun\", \"work well\" and \"congratulations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Investigating the effect of training size on accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We increment the training size from 1000 to 25000 in increments of 1000 and examine the increase in accuracy as we increase the training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the vectorizer\n",
    "vectorizer = CountVectorizer(max_features=1000,analyzer='word',lowercase=True) #Tokenize at word level\n",
    "vectorizer.fit(alltrain.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 1000 Average F1-score: 77.57%\n",
      "Training size: 2000 Average F1-score: 79.22%\n",
      "Training size: 3000 Average F1-score: 79.96%\n",
      "Training size: 4000 Average F1-score: 80.56%\n",
      "Training size: 5000 Average F1-score: 81.76%\n",
      "Training size: 6000 Average F1-score: 82.57%\n",
      "Training size: 7000 Average F1-score: 82.83%\n",
      "Training size: 8000 Average F1-score: 83.71%\n",
      "Training size: 9000 Average F1-score: 84.24%\n",
      "Training size: 10000 Average F1-score: 84.52%\n",
      "Training size: 11000 Average F1-score: 84.58%\n",
      "Training size: 12000 Average F1-score: 84.76%\n",
      "Training size: 13000 Average F1-score: 84.97%\n",
      "Training size: 14000 Average F1-score: 85.18%\n",
      "Training size: 15000 Average F1-score: 85.33%\n",
      "Training size: 16000 Average F1-score: 85.59%\n",
      "Training size: 17000 Average F1-score: 85.51%\n",
      "Training size: 18000 Average F1-score: 85.68%\n",
      "Training size: 19000 Average F1-score: 85.70%\n",
      "Training size: 20000 Average F1-score: 85.72%\n",
      "Training size: 21000 Average F1-score: 85.82%\n",
      "Training size: 22000 Average F1-score: 85.91%\n",
      "Training size: 23000 Average F1-score: 86.08%\n",
      "Training size: 24000 Average F1-score: 86.02%\n",
      "Training size: 25000 Average F1-score: 85.95%\n"
     ]
    }
   ],
   "source": [
    "#Train the model with varying sizes of train data\n",
    "F1list = [] #Track the F1 scores\n",
    "trainSize = [] #Track our training size\n",
    "for i in range(1,26):\n",
    "    trainSize.append(i*1000)\n",
    "    #Create a model\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    #Train with our dataset\n",
    "    model.fit(vectorizer.transform(train.data[0:i*1000]), train.target[0:i*1000])\n",
    "    #Vectorize our test data.\n",
    "    test_pred = model.predict(vectorizer.transform(test.data))\n",
    "    #Determine our F1 score\n",
    "    F1 = 100*f1_score(test.target, test_pred, average='macro')\n",
    "    print (\"Training size: %d Average F1-score: %3.2f%%\" % (i*1000, F1))\n",
    "    F1list.append(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Function to plot trainsize vs Fscore\n",
    "def plotTrainsizeFscore(trainSize,F1list):\n",
    "    plt.figure(figsize=(8, 4)) \n",
    "    plt.plot(trainSize,F1list,color='blue')\n",
    "    plt.xlabel('Training size', fontsize=10)\n",
    "    plt.ylabel('F-score %', fontsize=10)\n",
    "    plt.title('Learning Curve',fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot our F1 against data Size\n",
    "plotTrainsizeFscore(trainSize,F1list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I observe that our logistic regression model was suprisingly accurate even when training even with a minimal of 1000 samples. It seems that given only 1000 samples, our model could identify the sentiment relatively well\n",
    "\n",
    "I observe that as the training size increases, the F1 score of the model increases. For example, with only 1000 training samples we can achieve an accuracy of 77.6% while with 5,000 training samples we can achieve a score of 81.8%. This is to be expected because the more training examples we have, the better the predicting capability and generalization to the unseen test the model is.\n",
    "\n",
    "I also observe that as the training size increases, the rate of gain in F1 of adding on an additional 1000 sample decreased. Simply put the F1 score did not increase linearlly to the size of the Training. There appears to be a log relationship.\n",
    "\n",
    "Between 1000 and 2000 examples, the F score increased 1.65% Between 2000 and 4000 it increased 1.34%. Between 4000 and 8000 it increased 3.15%. Between 8000 and 16000 it increased 1.88%. \n",
    "\n",
    "Following this observed relationship, I would expect an increase of around 2% for every doubling in training size. Hence, I expect an increase of another 2% to 88% if we add another 25000 examples. (Although this is not guranteed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Investigating the effect of featureSize and trainingSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training size varies in increments of 5000 while our feature size (words) varies between 100, 1000 and 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorzing with 100 features\n",
      "Training size: 1000 Average F1-score: 69.86%\n",
      "Training size: 5000 Average F1-score: 72.74%\n",
      "Training size: 10000 Average F1-score: 73.22%\n",
      "Training size: 15000 Average F1-score: 73.32%\n",
      "Training size: 20000 Average F1-score: 73.42%\n",
      "Training size: 25000 Average F1-score: 73.22%\n",
      "Learning curve plot vectorized with 100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorzing with 1000 features\n",
      "Training size: 1000 Average F1-score: 77.57%\n",
      "Training size: 5000 Average F1-score: 81.76%\n",
      "Training size: 10000 Average F1-score: 84.52%\n",
      "Training size: 15000 Average F1-score: 85.33%\n",
      "Training size: 20000 Average F1-score: 85.72%\n",
      "Training size: 25000 Average F1-score: 85.95%\n",
      "Learning curve plot vectorized with 1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorzing with 10000 features\n",
      "Training size: 1000 Average F1-score: 79.78%\n",
      "Training size: 5000 Average F1-score: 84.63%\n",
      "Training size: 10000 Average F1-score: 85.14%\n",
      "Training size: 15000 Average F1-score: 85.06%\n",
      "Training size: 20000 Average F1-score: 85.40%\n",
      "Training size: 25000 Average F1-score: 85.52%\n",
      "Learning curve plot vectorized with 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for featureSize in [100, 1000, 10000]:\n",
    "    print(\"Vectorzing with %d features\" % (featureSize))\n",
    "    #Create the vectorizer\n",
    "    vectorizer = CountVectorizer(max_features=featureSize,analyzer='word',lowercase=True) #Tokenize at word level\n",
    "    vectorizer.fit(alltrain.data)\n",
    "\n",
    "    #Train the model with varying sizes of train data\n",
    "    F1list = [] #Track the F1 scores\n",
    "    trainSize = [] #Track our training size\n",
    "    for i in [1,5,10,15,20,25]:\n",
    "        trainSize.append(i*1000)\n",
    "        #Create a model\n",
    "        model = LogisticRegression(solver='liblinear')\n",
    "        #Train with our dataset\n",
    "        model.fit(vectorizer.transform(train.data[0:i*1000]), train.target[0:i*1000])\n",
    "        #Vectorize our test data.\n",
    "        test_pred = model.predict(vectorizer.transform(test.data))\n",
    "        #Determine our F1 score\n",
    "        F1 = 100*f1_score(test.target, test_pred, average='macro')\n",
    "        print (\"Training size: %d Average F1-score: %3.2f%%\" % (i*1000, F1))\n",
    "        F1list.append(F1)\n",
    "        \n",
    "    #Plot our F1 against data Size\n",
    "    print(\"Learning curve plot vectorized with %d\" % (featureSize))\n",
    "    plotTrainsizeFscore(trainSize,F1list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was an interesting investigation. We learnt from ยง5 that as the training size increases, the F-score increases (although non-linearly). In this section, we conducted the same training size variation, but using different levels of features (words) namely features of 100, 1000 and 10000. What I observed was that not only did the F1-score change, but the profile of the training curve also changed with different number of features.\n",
    "\n",
    "First, using only 100 word features, we see that the F1 score at with a training_size of 1000 was the lowest at 69.86%. With 1000 word features, this increased to 77.57% and with 10,000 this climbed to 79.78%. It seems that as the number of word features increase, the F-score also increases. \n",
    "\n",
    "However, this holds less weight when we train with the full training_size of 25000. At 100 word features, the F1 score was 73.22% and at 1000 features increased to 85.95% as expected. However, with 10,000 features, the score actually decreased to 85.52%.This could suggest that there are only a certain number of \"indicator\" words utilized by our model. After around 1000 features, most of the additional features are perhaps not useful to our predictor. In addition having more features could result in overfitting of our model. This means that after training, our model will generalize less well to the unseen test set.\n",
    "\n",
    "The learning curve profile also varied between different feature settings. For instance, with 100 features, the model quickly learnt the most optimal model. After 5000-10000 training examples, the model did not imrpove the score. It suggests that maybe the model learnt the most optimal parameters. Furthurmore, this score actually dropped after 20,000 instances suggesting either overfitting or lack of features to search over since the feature space is so constrained.\n",
    "\n",
    "With 1000 features, the model could continually and gradually improve its score with added training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Investigating the effect of TfidVectorizer, and MultinomialNaiveBayes model and training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing our vectorizer and model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized with CountVectorizer and trained with LogisticRegression algorithm\n",
      "Training size: 1000 Average F1-score: 77.57%\n",
      "Training size: 5000 Average F1-score: 81.76%\n",
      "Training size: 25000 Average F1-score: 85.95%\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer and LogisticRegression\n",
    "vectorizer = CountVectorizer(max_features=1000,analyzer='word',lowercase=True)\n",
    "vectorizer.fit(alltrain.data)\n",
    "print(\"Vectorized with CountVectorizer and trained with LogisticRegression algorithm\")\n",
    "for trainSize in [1000, 5000, 25000]:\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(vectorizer.transform(train.data[0:trainSize]), train.target[0:trainSize])\n",
    "    #Vectorize our test data.\n",
    "    test_pred = model.predict(vectorizer.transform(test.data))\n",
    "    #Determine our F1 score\n",
    "    F1 = 100*f1_score(test.target, test_pred, average='macro')\n",
    "    print(\"Training size: %d Average F1-score: %3.2f%%\" % (trainSize, F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized with CountVectorizer and trained with MultinomialNaiveBayes algorithm\n",
      "Training size: 1000 Average F1-score: 79.31%\n",
      "Training size: 5000 Average F1-score: 80.68%\n",
      "Training size: 25000 Average F1-score: 80.92%\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer and MultinomialNaiveBayes\n",
    "vectorizer = CountVectorizer(max_features=1000,analyzer='word',lowercase=True)\n",
    "vectorizer.fit(alltrain.data)\n",
    "print(\"Vectorized with CountVectorizer and trained with MultinomialNaiveBayes algorithm\")\n",
    "for trainSize in [1000, 5000, 25000]:\n",
    "    model = MultinomialNB()\n",
    "    model.fit(vectorizer.transform(train.data[0:trainSize]), train.target[0:trainSize])\n",
    "    #Vectorize our test data.\n",
    "    test_pred = model.predict(vectorizer.transform(test.data))\n",
    "    #Determine our F1 score\n",
    "    F1 = 100*f1_score(test.target, test_pred, average='macro')\n",
    "    print(\"Training size: %d Average F1-score: %3.2f%%\" % (trainSize, F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized with TfidVectorizer and trained with MultinomialNaiveBayes algorithm\n",
      "Training size: 1000 Average F1-score: 81.23%\n",
      "Training size: 5000 Average F1-score: 82.91%\n",
      "Training size: 25000 Average F1-score: 83.28%\n"
     ]
    }
   ],
   "source": [
    "#TfidVectorizer and MultinomialNaiveBayes\n",
    "vectorizer = TfidfVectorizer(max_features=1000,analyzer='word',lowercase=True)\n",
    "vectorizer.fit(alltrain.data)\n",
    "print(\"Vectorized with TfidVectorizer and trained with MultinomialNaiveBayes algorithm\")\n",
    "for trainSize in [1000, 5000, 25000]:\n",
    "    model = MultinomialNB()\n",
    "    model.fit(vectorizer.transform(train.data[0:trainSize]), train.target[0:trainSize])\n",
    "    #Vectorize our test data.\n",
    "    test_pred = model.predict(vectorizer.transform(test.data))\n",
    "    #Determine our F1 score\n",
    "    F1 = 100*f1_score(test.target, test_pred, average='macro')\n",
    "    print(\"Training size: %d Average F1-score: %3.2f%%\" % (trainSize, F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized with TfidVectorizer and trained with LogisticRegression\n",
      "Training size: 1000 Average F1-score: 80.69%\n",
      "Training size: 5000 Average F1-score: 84.68%\n",
      "Training size: 25000 Average F1-score: 86.34%\n"
     ]
    }
   ],
   "source": [
    "#TfidVectorizer and LogisticRegression\n",
    "vectorizer = TfidfVectorizer(max_features=1000,analyzer='word',lowercase=True)\n",
    "vectorizer.fit(alltrain.data)\n",
    "print(\"Vectorized with TfidVectorizer and trained with LogisticRegression\")\n",
    "for trainSize in [1000, 5000, 25000]:\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(vectorizer.transform(train.data[0:trainSize]), train.target[0:trainSize])\n",
    "    #Vectorize our test data.\n",
    "    test_pred = model.predict(vectorizer.transform(test.data))\n",
    "    #Determine our F1 score\n",
    "    F1 = 100*f1_score(test.target, test_pred, average='macro')\n",
    "    print(\"Training size: %d Average F1-score: %3.2f%%\" % (trainSize, F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first setting of note that applies across the different scales is the size of the training data. In these scenarios, as the size of the training data increases, so does the performance. \n",
    "\n",
    "However, certain setting combinations (vectorizer and model) gain a higher performance increase from an increase in the size of training. The most significant is perhaps using CountVectorizer and Logistic regression. In this combination, the performance increased from 77.6% to 86% when we used the full training data (1000 to 25000). The least significant is using CountVectorizer and MultinomialNaiveBayes algorithm which only resulted in an performance increase from 79.3% to 81% when the train data size was increased from 1000 to 25000.\n",
    "\n",
    "Using MultinomialNaiveBayes seems to boost the performance (when compared to LogisticRegression) in all cases when a low training size is used (1000), but decrease the performance when more training data is given (5000+). Using TfidVectorizer also seems to increas the performance (when compared to CountVectorizer) for both training algorithms and across all scales of data. \n",
    "\n",
    "The best performing setting when given a low amount of training data (1000) was using TfidVectorizer with MultinomialNaiveBayes with a score of 81.23% while the worst was CountVectorizer and LogisticRegression that resulted in a score of 77.6%. This situation was negated when we used the full training set (25000). In this case the best performing algorithm was TfidVectorizer with LogisticRegression while the worst was CountVectorizer and MultinomialNaiveBayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following from the above observations, I would elect to use different settings depending on the amount of training data I have. If I had a small amount of training data (1000) I would use (TfidVectorizer and MultinomialNaiveBayes). If I had a higher amount of training data (5000+) I would use (TfidVectorizer and LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Building a Word2Vec model for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Gensim package implementation of Word2Vec \n",
    "import gensim\n",
    "# Import Word2Vec from Gensim\n",
    "from gensim.models import Word2Vec\n",
    "#Use the same tokenization strategy as in previous sections\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "wordtokenizer=CountVectorizer().build_analyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 34s, sys: 4.31 s, total: 4min 39s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "#A Word2Vec model taking in array of vectorized words\n",
    "#Using the following settings: word vector size=150, model window=10, min_count of words to include=2\n",
    "%time wv_model = gensim.models.Word2Vec([wordtokenizer(str(i)) for i in alltrain.data],size=150,window=10,min_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of our learnt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word = Queen\n",
      "Token = queen\n",
      "Most Similar:\n",
      "[('princess', 0.6992750763893127), ('bride', 0.6394477486610413), ('goddess', 0.6373637914657593)]\n",
      "------------\n",
      "Word Vector(first 10):\n",
      "[-0.642914   -0.41942874 -0.07933773  1.1781713  -1.8192645  -0.42068008\n",
      "  0.19961537 -0.7094885   2.0396817  -0.23580664]\n",
      "Word Vector length:\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "#Given a word, get the top 3 similar words and display the interal word vector.\n",
    "word = \"Queen\"\n",
    "#Tokenize word, taking the first token in the list\n",
    "tokword=wordtokenizer(word)[0]\n",
    "\n",
    "print(\"Word = %s\" % word)\n",
    "print(\"Token = %s\" % tokword)\n",
    "\n",
    "#Proceed if word is in the model\n",
    "if (tokword in wv_model.wv.vocab):\n",
    "    print(\"Most Similar:\")\n",
    "    print(wv_model.wv.most_similar(tokword,topn=3))\n",
    "    print(\"------------\")\n",
    "    print(\"Word Vector(first 10):\")\n",
    "    print(wv_model.wv[tokword][0:10])\n",
    "    print(\"Word Vector length:\")\n",
    "    print(len(wv_model.wv[tokword]))\n",
    "else:\n",
    "    print(\"Unknown Word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france - paris + berlin = \n",
      "[('germany', 0.769467830657959), ('spain', 0.7347414493560791), ('poland', 0.7131622433662415)]\n"
     ]
    }
   ],
   "source": [
    "#Analogies: A1 to B1 is like what to B2 <br> (A1 - B1 + B2 = A2) <br> *e.g. King - Man + Woman = Queen*\n",
    "A1_word = \"France\" \n",
    "B1_word = \"Paris\"\n",
    "B2_word = \"Berlin\"\n",
    "\n",
    "#Tokenize words\n",
    "A1_tokword=wordtokenizer(A1_word)[0]\n",
    "B1_tokword=wordtokenizer(B1_word)[0]\n",
    "B2_tokword=wordtokenizer(B2_word)[0]\n",
    "\n",
    "#Analogy formula\n",
    "print(\"%s - %s + %s = \" % (A1_tokword,B1_tokword,B2_tokword))\n",
    "\n",
    "#Check if our word is in the vocab of our model\n",
    "if (A1_tokword in wv_model.wv.vocab and B1_tokword in wv_model.wv.vocab and B2_tokword in wv_model.wv.vocab):\n",
    "    print(wv_model.wv.most_similar(positive=[A1_tokword,B2_tokword],negative=[B1_tokword],topn=3))\n",
    "else:\n",
    "    print(\"One of the given words is not known\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: the young king told us he was angry | the prince said he was mad\n",
      "Sentence Similarity 75.352\n",
      "Sentences: twinkle twinkle little star | what is the meaning of life\n",
      "Sentence Similarity 0.373\n"
     ]
    }
   ],
   "source": [
    "#Sentence Similarty:  sentence1 to sentence2 \n",
    "#Word2Vec is for words so to evaluate sentences, we map words into a single vector\n",
    "\n",
    "#Map senteneces to a single vecvtor. Tokenize and filter unknown words.\n",
    "def meanW2VTransform (sent):\n",
    "    return np.mean(\n",
    "        [wv_model.wv[wordi] for wordi in list(filter(lambda i : i in wv_model.wv.vocab, wordtokenizer(str(sent))))],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "#Use cosine similarity to measure the distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine\n",
    "\n",
    "sentence1 = \"the young king told us he was angry\"\n",
    "sentence2 = \"the prince said he was mad\"\n",
    "print(\"Sentences: %s | %s\" % (sentence1, sentence2))\n",
    "print(\"Sentence Similarity %3.3f\" %(100*cosine([meanW2VTransform(sentence1)],[meanW2VTransform(sentence2)])))\n",
    "\n",
    "sentence1 = \"twinkle twinkle little star\"\n",
    "sentence2 = \"what is the meaning of life\"\n",
    "print(\"Sentences: %s | %s\" % (sentence1, sentence2))\n",
    "print(\"Sentence Similarity %3.3f\" %(100*cosine([meanW2VTransform(sentence1)],[meanW2VTransform(sentence2)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a5DNa04kjrPf"
   },
   "source": [
    "#### Sentence-level sentiment analysis using a vectorizer based on average vectors of words in a sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  = 86.81%\n",
      "Average Precision = 86.81%\n",
      "Average Recall    = 86.81%\n",
      "Average F1-score  = 86.81%\n"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis using Logistic Regression and a Word2Vec-based vectorizer.\n",
    "\n",
    "# Same tokenization strategy as above section\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "wordtokenizer=CountVectorizer().build_analyzer()\n",
    "\n",
    "# Reduce sentences to the mean word vector of that sentence.\n",
    "def meanW2VTransform (sent):\n",
    "    return np.mean(\n",
    "        [wv_model.wv[wordi] for wordi in list(filter(lambda i : i in wv_model.wv.vocab, wordtokenizer(str(sent))))],\n",
    "        axis=0\n",
    "    )\n",
    "  \n",
    "\n",
    "# Create our LR model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "WordLRModel = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Train\n",
    "WordLRModel.fit([meanW2VTransform(str(i)) for i in  train.data], train.target)\n",
    "\n",
    "# Predict\n",
    "test_pred = WordLRModel.predict([meanW2VTransform(str(i)) for i in  test.data])\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "print (\"Accuracy  = %3.2f%%\" % (100*accuracy_score(test.target, test_pred)))\n",
    "print (\"Average Precision = %3.2f%%\" % (100*precision_score(test.target, test_pred, average='macro')))\n",
    "print (\"Average Recall    = %3.2f%%\" % (100*recall_score(test.target, test_pred, average='macro')))\n",
    "print (\"Average F1-score  = %3.2f%%\" % (100*f1_score(test.target, test_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Searching for optimal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the most optimal parameter for my model, I will search over the following parameters:\n",
    "\n",
    "size={75, 150, 300}\n",
    "\n",
    "window={5,10, 20}\n",
    "\n",
    "training data size={1000, 5000, 25,000}\n",
    "\n",
    "For a total of 3x3x3=27 settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 75 | window 5 | trainSize 1000\n",
      "Average F1-score  = 83.51%\n",
      "size: 75 | window 5 | trainSize 5000\n",
      "Average F1-score  = 84.07%\n",
      "size: 75 | window 5 | trainSize 25000\n",
      "Average F1-score  = 84.41%\n",
      "size: 75 | window 10 | trainSize 1000\n",
      "Average F1-score  = 84.53%\n",
      "size: 75 | window 10 | trainSize 5000\n",
      "Average F1-score  = 85.39%\n",
      "size: 75 | window 10 | trainSize 25000\n",
      "Average F1-score  = 85.59%\n",
      "size: 75 | window 20 | trainSize 1000\n",
      "Average F1-score  = 85.56%\n",
      "size: 75 | window 20 | trainSize 5000\n",
      "Average F1-score  = 86.22%\n",
      "size: 75 | window 20 | trainSize 25000\n",
      "Average F1-score  = 86.61%\n",
      "size: 150 | window 5 | trainSize 1000\n",
      "Average F1-score  = 84.44%\n",
      "size: 150 | window 5 | trainSize 5000\n",
      "Average F1-score  = 85.72%\n",
      "size: 150 | window 5 | trainSize 25000\n",
      "Average F1-score  = 86.29%\n",
      "size: 150 | window 10 | trainSize 1000\n",
      "Average F1-score  = 85.56%\n",
      "size: 150 | window 10 | trainSize 5000\n",
      "Average F1-score  = 86.56%\n",
      "size: 150 | window 10 | trainSize 25000\n",
      "Average F1-score  = 86.82%\n",
      "size: 150 | window 20 | trainSize 1000\n",
      "Average F1-score  = 85.98%\n",
      "size: 150 | window 20 | trainSize 5000\n",
      "Average F1-score  = 87.11%\n",
      "size: 150 | window 20 | trainSize 25000\n",
      "Average F1-score  = 87.58%\n",
      "size: 300 | window 5 | trainSize 1000\n",
      "Average F1-score  = 84.85%\n",
      "size: 300 | window 5 | trainSize 5000\n",
      "Average F1-score  = 86.30%\n",
      "size: 300 | window 5 | trainSize 25000\n",
      "Average F1-score  = 87.10%\n",
      "size: 300 | window 10 | trainSize 1000\n",
      "Average F1-score  = 85.60%\n",
      "size: 300 | window 10 | trainSize 5000\n",
      "Average F1-score  = 86.81%\n",
      "size: 300 | window 10 | trainSize 25000\n",
      "Average F1-score  = 87.72%\n",
      "size: 300 | window 20 | trainSize 1000\n",
      "Average F1-score  = 86.10%\n",
      "size: 300 | window 20 | trainSize 5000\n",
      "Average F1-score  = 87.38%\n",
      "size: 300 | window 20 | trainSize 25000\n",
      "Average F1-score  = 88.25%\n"
     ]
    }
   ],
   "source": [
    "for size in [75,150,300]:\n",
    "    for window in [5, 10, 20]:\n",
    "        for trainSize in [1000,5000,25000]:\n",
    "            #Create our Word2Vec vectorizer with the required parameters\n",
    "            wv_model = gensim.models.Word2Vec([wordtokenizer(str(i)) for i in alltrain.data],size=size,window=window,min_count=2)\n",
    "            #Create the LR model.\n",
    "            model = LogisticRegression(solver='liblinear')\n",
    "            #Train with trainSize\n",
    "            model.fit([meanW2VTransform(str(i)) for i in  train.data[0:trainSize]], train.target[0:trainSize])\n",
    "            #Predict on our test data\n",
    "            test_pred = model.predict([meanW2VTransform(str(i)) for i in  test.data])\n",
    "            #Evaluate the F1 score\n",
    "            print(\"size: %d | window %d | trainSize %d\" %(size,window,trainSize))\n",
    "            print (\"Average F1-score  = %3.2f%%\" % (100*f1_score(test.target, test_pred, average='macro')))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found quite interesting relationships between the various settings. First of all, across all the setting parameters, when the trainSize increased, so did the performance. For instance, with a feature size of 300 and window of 30, when the trainSize was increased from 1000 to 25000, the performance of the setting increased from 86% to 88%. What is suprising to me however is the performance with only a training size of 1000. The model could predict quite accuracy with even a small trainingSize of 1000.\n",
    "\n",
    "Taking a look at the size, which is the dimensionality of the word vectors, I noticed that when the size was increased (while keeping the other settings constant) then the performance generally increased. For example, when the size was increased from 75 to 300, across all the settings the performance increased. This is probably because with a higher dimension, the word vectors contain a greater featuress that can be used differentiate each other.\n",
    "\n",
    "Following the above point, It also appears that the greatest performance gains from increasing the trainSize was when the vector dimension (size) setting was the highest. For example, (keeping a window of 20) when the size was 75 and we increased the train size from 1000 to 25000 we went from 85.55% to 86.65% representing a 1.1% increase. On the other hand at a size of 300, when we increased the train size from 1000 to 25000 we went from 86.14% to 88.15% representing a 2% increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Building a Doc2Vec model for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec is tool for representing documents as vectors. It builds on the Word2Vec model and extends it.\n",
    "Doc2Vec was introduced in a paper by Le and Mikolov (ICML 2014) titled \"[Distributed Representations of Sentences and Documents](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)\".\n",
    "\n",
    "We will use the [Gensim package implementation of Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html), specifically, [Scikit-learn wrapper for it in Gensim](https://radimrehurek.com/gensim/sklearn_api/d2vmodel.html). \n",
    "\n",
    "We start with training a Doc2Vec model and use it in a sentiment analyzer. Then we studying Doc2Vec's behavior under different settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "#Use the same vectorizer as previously\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "wordtokenizer=CountVectorizer().build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim Doc2Vec transformer\n",
    "from gensim.sklearn_api import D2VTransformer\n",
    "\n",
    "# We create the D2V Vectorizer.\n",
    "# size โ Dimensionality of the feature vectors.\n",
    "# iter โ Number of epochs to iterate over corpus\n",
    "D2Vectorizer = D2VTransformer(dm=0, size=100, negative=5, hs=0, min_count=2, sample=0, iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D2VTransformer(alpha=0.025, batch_words=10000, cbow_mean=1, comment=None,\n",
       "        dbow_words=0, dm=0, dm_concat=0, dm_mean=None, dm_tag_count=1,\n",
       "        docvecs=None, docvecs_mapfile=None,\n",
       "        hashfxn=<built-in function hash>, hs=0, iter=20,\n",
       "        max_vocab_size=None, min_alpha=0.0001, min_count=2, negative=5,\n",
       "        sample=0, seed=1, size=100, sorted_vocab=1, trim_rule=None,\n",
       "        window=5, workers=3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2Vectorizer.fit([wordtokenizer(str(i)) for i in alltrain.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a LogisticRegression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "DocLRModel = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#Tectorize with our Doc2Vec method and then train the LogisticRegression mode.\n",
    "DocLRModel.fit(D2Vectorizer.transform([wordtokenizer(str(i)) for i in train.data]), train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  = 88.01%\n",
      "Average Precision = 88.03%\n",
      "Average Recall    = 88.01%\n",
      "Average F1-score  = 88.01%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate over the test set\n",
    "test_pred = DocLRModel.predict(D2Vectorizer.transform([wordtokenizer(str(i)) for i in  test.data]))\n",
    "\n",
    "print (\"Accuracy  = %3.2f%%\" % (100*accuracy_score(test.target, test_pred)))\n",
    "print (\"Average Precision = %3.2f%%\" % (100*precision_score(test.target, test_pred, average='macro')))\n",
    "print (\"Average Recall    = %3.2f%%\" % (100*recall_score(test.target, test_pred, average='macro')))\n",
    "print (\"Average F1-score  = %3.2f%%\" % (100*f1_score(test.target, test_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Searching for optimal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the most optimal parameter for my model, I will search over the following parameters:\n",
    "\n",
    "size={50, 100, 200}\n",
    "\n",
    "iter={1,5, 20}\n",
    "\n",
    "training data size={1000, 5000, 25,000}\n",
    "\n",
    "For a total of 3x3x3=27 settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 50 | iter: 1 | trainSize: 1000\n",
      "Average F1-score  = 77.02%\n",
      "size: 50 | iter: 1 | trainSize: 5000\n",
      "Average F1-score  = 77.64%\n",
      "size: 50 | iter: 1 | trainSize: 25000\n",
      "Average F1-score  = 78.50%\n",
      "size: 50 | iter: 5 | trainSize: 1000\n",
      "Average F1-score  = 85.70%\n",
      "size: 50 | iter: 5 | trainSize: 5000\n",
      "Average F1-score  = 86.13%\n",
      "size: 50 | iter: 5 | trainSize: 25000\n",
      "Average F1-score  = 86.43%\n",
      "size: 50 | iter: 20 | trainSize: 1000\n",
      "Average F1-score  = 87.44%\n",
      "size: 50 | iter: 20 | trainSize: 5000\n",
      "Average F1-score  = 87.72%\n",
      "size: 50 | iter: 20 | trainSize: 25000\n",
      "Average F1-score  = 87.92%\n",
      "size: 100 | iter: 1 | trainSize: 1000\n",
      "Average F1-score  = 76.79%\n",
      "size: 100 | iter: 1 | trainSize: 5000\n",
      "Average F1-score  = 77.42%\n",
      "size: 100 | iter: 1 | trainSize: 25000\n",
      "Average F1-score  = 78.31%\n",
      "size: 100 | iter: 5 | trainSize: 1000\n",
      "Average F1-score  = 84.86%\n",
      "size: 100 | iter: 5 | trainSize: 5000\n",
      "Average F1-score  = 86.10%\n",
      "size: 100 | iter: 5 | trainSize: 25000\n",
      "Average F1-score  = 86.42%\n",
      "size: 100 | iter: 20 | trainSize: 1000\n",
      "Average F1-score  = 86.39%\n",
      "size: 100 | iter: 20 | trainSize: 5000\n",
      "Average F1-score  = 87.53%\n",
      "size: 100 | iter: 20 | trainSize: 25000\n",
      "Average F1-score  = 87.93%\n",
      "size: 200 | iter: 1 | trainSize: 1000\n",
      "Average F1-score  = 75.89%\n",
      "size: 200 | iter: 1 | trainSize: 5000\n",
      "Average F1-score  = 76.80%\n",
      "size: 200 | iter: 1 | trainSize: 25000\n",
      "Average F1-score  = 77.82%\n",
      "size: 200 | iter: 5 | trainSize: 1000\n",
      "Average F1-score  = 84.89%\n",
      "size: 200 | iter: 5 | trainSize: 5000\n",
      "Average F1-score  = 86.00%\n",
      "size: 200 | iter: 5 | trainSize: 25000\n",
      "Average F1-score  = 86.75%\n",
      "size: 200 | iter: 20 | trainSize: 1000\n",
      "Average F1-score  = 83.58%\n",
      "size: 200 | iter: 20 | trainSize: 5000\n",
      "Average F1-score  = 85.86%\n",
      "size: 200 | iter: 20 | trainSize: 25000\n",
      "Average F1-score  = 86.93%\n"
     ]
    }
   ],
   "source": [
    "for size in [50,100,200]:\n",
    "    for iter in [1, 5, 20]:\n",
    "        for trainSize in [1000,5000,25000]:\n",
    "            #Create our vectorizer with the correct parameters:\n",
    "            D2Vectorizer = D2VTransformer(dm=0, size=size, negative=5, hs=0, min_count=2, sample=0, iter=iter)\n",
    "            # Training the vectorizer requires training data in the form of array of sentences consisting of arrays of words.\n",
    "            D2Vectorizer.fit([wordtokenizer(str(i)) for i in alltrain.data])\n",
    "            #Create our logistic regression model\n",
    "            model = LogisticRegression(solver='liblinear')\n",
    "            #Train the model with the required trainSize\n",
    "            model.fit(D2Vectorizer.transform([wordtokenizer(str(i)) for i in train.data[0:trainSize]]), train.target[0:trainSize])\n",
    "            #Evaluate over the test set\n",
    "            test_pred = model.predict(D2Vectorizer.transform([wordtokenizer(str(i)) for i in  test.data]))\n",
    "            #Print results\n",
    "            print(\"size: %d | iter: %d | trainSize: %d\" %(size,iter,trainSize))\n",
    "            print (\"Average F1-score  = %3.2f%%\" % (100*f1_score(test.target, test_pred, average='macro')))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this parameter search, I noticed some interesting observations.\n",
    "\n",
    "Not suprisingly, every time the trainSize was increased, the performance of the model also increased. This is because the model has more examples to train over and so can predict the test set better.\n",
    "\n",
    "Furthurmore, as discussed in section 8, when the dimensionality of the document vector (size) increased, the performance also increased in most situations. However, this did not hold for every single case. For example with (20 iterations and a train size of 1000) when we increased the feature size from 100 to 200, the performance decreased from 86.55% to 84.11%, marking a 2.44% decrease. There could be many causes, but this is likely because increasing the dimensionality of the feature vector lends to a higher likelihood of overfitting. This means that the model was less able to generalize over the unseen test set. \n",
    "\n",
    "When a low vector size, the system performed better when both the trainSize and the number of iterations was higher (as it has lower likelihood of overfitting). Overall, the best system had the following parameters (size: 100 | iter: 20 | trainSize: 25000) performing with a F-score of 88.18% while the worst system used (size: 200 | iter: 1 | trainSize: 1000) performing with a F-score of F1-score  = 75.92%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Support Vector Machine with stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using linear SVM to train after running PorterStemmer, tokenizer and Doc2Vec vectorization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, the porter stemmer was applied to stem the movie review text at a sentence level. This was done in order to reduce the space of unnecessary inflections at the word level that don't contribute much to the semantic understanding of the review.\n",
    "\n",
    "2. Second, the sentences were tokenized at both a unigram and bi-gram level. The idea behind this step is to move away from a bag-of-words level and into a phrase level understanding of the reviews. This should help classify cases where the words used in the review may be positive, but negated at a bi-gram level. For instance, `Awfully good`\n",
    "\n",
    "3. Second, the words were vectorized before fed into the Doc2Vec model. This was done because we want to capture the relationships between phrases at a higher level than a simple bag-of-words of bag-of-phrases model.\n",
    "\n",
    "4. All of this was fed into a linear SVM in order to give us our classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use porter stemmer\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from sklearn import svm\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigram tokenizer\n",
    "wordtokenizer=CountVectorizer(ngram_range=(1,2)).build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our vectorizer with the parameters:\n",
    "D2Vectorizer = D2VTransformer(dm=0, size=150, workers=4, negative=5, hs=0, min_count=5, sample=0, iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D2VTransformer(alpha=0.025, batch_words=10000, cbow_mean=1, comment=None,\n",
       "        dbow_words=0, dm=0, dm_concat=0, dm_mean=None, dm_tag_count=1,\n",
       "        docvecs=None, docvecs_mapfile=None,\n",
       "        hashfxn=<built-in function hash>, hs=0, iter=20,\n",
       "        max_vocab_size=None, min_alpha=0.0001, min_count=5, negative=5,\n",
       "        sample=0, seed=1, size=150, sorted_vocab=1, trim_rule=None,\n",
       "        window=5, workers=4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the vectorizer requires training data in the form of array of sentences consisting of arrays of words.\n",
    "D2Vectorizer.fit([wordtokenizer(stemmer.stem_sentence(str(i))) for i in alltrain.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=2000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the SVM\n",
    "svm2gram = svm.LinearSVC(max_iter=2000, penalty='l2', C=1.0)\n",
    "svm2gram.fit(D2Vectorizer.transform([wordtokenizer(stemmer.stem_sentence(str(i))) for i in train.data]), train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-score  = 90.40%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "test_pred = svm2gram.predict(D2Vectorizer.transform([wordtokenizer(stemmer.stem_sentence(str(i))) for i in  test.data]))\n",
    "print (\"Average F1-score  = %3.2f%%\" % (100*f1_score(test.target, test_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final F1 of the best model on the test set: 90.40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall this was the best model that ran on the test set. I did not conduct any more additional parameter searching with the SVM, but we can expect (from parameter searching in the previous sections) a 1-2% gain if we searched over all parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final attempt was to use ensemble learning with the three language models that were developed in sections 8, 9 and 10. Each model predicts the sentiment of the text independently and we take the most popular vote as the predicted sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "D2Vectorizer = D2VTransformer(dm=0, size=150, workers=4, negative=5, hs=0, min_count=5, sample=0, iter=15)\n",
    "D2Vectorizer.fit([wordtokenizer(str(i)) for i in alltrain.data])\n",
    "test_pred1 = svm2gram.predict(D2Vectorizer.transform([wordtokenizer(str(i)) for i in  test.data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "D2Vectorizer = D2VTransformer(dm=0, size=100, negative=5, hs=0, min_count=2, sample=0, iter=20)\n",
    "D2Vectorizer.fit([wordtokenizer(str(i)) for i in alltrain.data])\n",
    "test_pred2 = DocLRModel.predict(D2Vectorizer.transform([wordtokenizer(str(i)) for i in  test.data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordLRModel = LogisticRegression(solver='liblinear')\n",
    "WordLRModel.fit([meanW2VTransform(str(i)) for i in  train.data], train.target)\n",
    "test_pred3 = WordLRModel.predict([meanW2VTransform(str(i)) for i in  test.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-score  = 88.12%\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(len(test_pred1)):\n",
    "    pos = 0\n",
    "    pos += test_pred1[i]\n",
    "    pos += test_pred2[i]\n",
    "    pos += test_pred3[i]\n",
    "    if pos >= 2:\n",
    "        result.append(1)\n",
    "    else:\n",
    "        result.append(0)\n",
    "\n",
    "print (\"Average F1-score  = %3.2f%%\" % (100*f1_score(result, test.target, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this score is even lower than using our single best model (Stemmed SVM with Doc2Vec). It appears that the other two models (Linear Doc2Vec) and (Linear Word2Vec) are quite correlated and when added together, overpowered the best classifier in the group (Stemmed SVM with Doc2Vec). A possible extension to this research is to weigh the predictions of each model depending on how accurate they are and to incorporate more learners."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
